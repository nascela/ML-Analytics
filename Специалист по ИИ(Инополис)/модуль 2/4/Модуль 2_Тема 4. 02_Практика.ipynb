{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тема \"Метод опорных векторов\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный метод также применяется для решения задачи классификации. В рассматриваемом примере мы продолжим классифицировать пациентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Загрузим библиотеки, которые нам потребуются\n",
    "from sklearn.preprocessing import StandardScaler    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Модуль 2_Тема 4. Онкология.csv') # загрузим данные из файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>842302</th>\n",
       "      <th>M</th>\n",
       "      <th>17.99</th>\n",
       "      <th>10.38</th>\n",
       "      <th>122.8</th>\n",
       "      <th>1001</th>\n",
       "      <th>0.1184</th>\n",
       "      <th>0.2776</th>\n",
       "      <th>0.3001</th>\n",
       "      <th>0.1471</th>\n",
       "      <th>...</th>\n",
       "      <th>25.38</th>\n",
       "      <th>17.33</th>\n",
       "      <th>184.6</th>\n",
       "      <th>2019</th>\n",
       "      <th>0.1622</th>\n",
       "      <th>0.6656</th>\n",
       "      <th>0.7119</th>\n",
       "      <th>0.2654</th>\n",
       "      <th>0.4601</th>\n",
       "      <th>0.1189</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>843786</td>\n",
       "      <td>M</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.1578</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>...</td>\n",
       "      <td>15.47</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     842302  M  17.99  10.38   122.8    1001   0.1184   0.2776  0.3001  \\\n",
       "0    842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869   \n",
       "1  84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974   \n",
       "2  84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414   \n",
       "3  84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980   \n",
       "4    843786  M  12.45  15.70   82.57   477.1  0.12780  0.17000  0.1578   \n",
       "\n",
       "    0.1471  ...  25.38  17.33   184.6    2019  0.1622  0.6656  0.7119  0.2654  \\\n",
       "0  0.07017  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "1  0.12790  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "2  0.10520  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "3  0.10430  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "4  0.08089  ...  15.47  23.75  103.40   741.6  0.1791  0.5249  0.5355  0.1741   \n",
       "\n",
       "   0.4601   0.1189  \n",
       "0  0.2750  0.08902  \n",
       "1  0.3613  0.08758  \n",
       "2  0.6638  0.17300  \n",
       "3  0.2364  0.07678  \n",
       "4  0.3985  0.12440  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() #Посмотрим на наши данные, видно, что заголовки столбцов отсутствуют."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568 entries, 0 to 567\n",
      "Data columns (total 32 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   842302    568 non-null    int64  \n",
      " 1   M         568 non-null    object \n",
      " 2   17.99     568 non-null    float64\n",
      " 3   10.38     568 non-null    float64\n",
      " 4   122.8     568 non-null    float64\n",
      " 5   1001      568 non-null    float64\n",
      " 6   0.1184    568 non-null    float64\n",
      " 7   0.2776    568 non-null    float64\n",
      " 8   0.3001    568 non-null    float64\n",
      " 9   0.1471    568 non-null    float64\n",
      " 10  0.2419    568 non-null    float64\n",
      " 11  0.07871   568 non-null    float64\n",
      " 12  1.095     568 non-null    float64\n",
      " 13  0.9053    568 non-null    float64\n",
      " 14  8.589     568 non-null    float64\n",
      " 15  153.4     568 non-null    float64\n",
      " 16  0.006399  568 non-null    float64\n",
      " 17  0.04904   568 non-null    float64\n",
      " 18  0.05373   568 non-null    float64\n",
      " 19  0.01587   568 non-null    float64\n",
      " 20  0.03003   568 non-null    float64\n",
      " 21  0.006193  568 non-null    float64\n",
      " 22  25.38     568 non-null    float64\n",
      " 23  17.33     568 non-null    float64\n",
      " 24  184.6     568 non-null    float64\n",
      " 25  2019      568 non-null    float64\n",
      " 26  0.1622    568 non-null    float64\n",
      " 27  0.6656    568 non-null    float64\n",
      " 28  0.7119    568 non-null    float64\n",
      " 29  0.2654    568 non-null    float64\n",
      " 30  0.4601    568 non-null    float64\n",
      " 31  0.1189    568 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info() #посмотрим на сводную информацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"id\", \"diagnosis\", \"radius_mean\", \"texture_mean\", \"perimeter_mean\", \"area_mean\",\n",
    "                                      \"smoothness_mean\", \"compactness_mean\", \"concavity_mean\", \"concave points_mean\",\n",
    "                                      \"symmetry_mean\", \"fractal_dimension_mean\", \"radius_se\", \"texture_se\",\n",
    "                                      \"perimeter_se\", \"area_se\", \"smoothness_se\", \"compactness_se\", \"concavity_se\",\n",
    "                                      \"concave points_se\", \"symmetry_se\", \"fractal_dimension_se\", \"radius_worst\",\n",
    "                                      \"texture_worst\", \"perimeter_worst\", \"area_worst\", \"smoothness_worst\",\n",
    "                                      \"compactness_worst\", \"concavity_worst\", \"concave points_worst\", \"symmetry_worst\",\n",
    "                                      \"fractal_dimension_worst\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.24300</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>843786</td>\n",
       "      <td>M</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>...</td>\n",
       "      <td>15.47</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.17410</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>844359</td>\n",
       "      <td>M</td>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>...</td>\n",
       "      <td>22.88</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>84458202</td>\n",
       "      <td>M</td>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>...</td>\n",
       "      <td>17.06</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.15560</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>844981</td>\n",
       "      <td>M</td>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>...</td>\n",
       "      <td>15.49</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.20600</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>84501001</td>\n",
       "      <td>M</td>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>...</td>\n",
       "      <td>15.09</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.22100</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>845636</td>\n",
       "      <td>M</td>\n",
       "      <td>16.02</td>\n",
       "      <td>23.24</td>\n",
       "      <td>102.70</td>\n",
       "      <td>797.8</td>\n",
       "      <td>0.08206</td>\n",
       "      <td>0.06669</td>\n",
       "      <td>0.03299</td>\n",
       "      <td>0.03323</td>\n",
       "      <td>...</td>\n",
       "      <td>19.19</td>\n",
       "      <td>33.88</td>\n",
       "      <td>123.80</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>0.1181</td>\n",
       "      <td>0.1551</td>\n",
       "      <td>0.1459</td>\n",
       "      <td>0.09975</td>\n",
       "      <td>0.2948</td>\n",
       "      <td>0.08452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>84610002</td>\n",
       "      <td>M</td>\n",
       "      <td>15.78</td>\n",
       "      <td>17.89</td>\n",
       "      <td>103.60</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.09710</td>\n",
       "      <td>0.12920</td>\n",
       "      <td>0.09954</td>\n",
       "      <td>0.06606</td>\n",
       "      <td>...</td>\n",
       "      <td>20.42</td>\n",
       "      <td>27.28</td>\n",
       "      <td>136.50</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>0.1396</td>\n",
       "      <td>0.5609</td>\n",
       "      <td>0.3965</td>\n",
       "      <td>0.18100</td>\n",
       "      <td>0.3792</td>\n",
       "      <td>0.10480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>846226</td>\n",
       "      <td>M</td>\n",
       "      <td>19.17</td>\n",
       "      <td>24.80</td>\n",
       "      <td>132.40</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>0.09740</td>\n",
       "      <td>0.24580</td>\n",
       "      <td>0.20650</td>\n",
       "      <td>0.11180</td>\n",
       "      <td>...</td>\n",
       "      <td>20.96</td>\n",
       "      <td>29.94</td>\n",
       "      <td>151.70</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.3903</td>\n",
       "      <td>0.3639</td>\n",
       "      <td>0.17670</td>\n",
       "      <td>0.3176</td>\n",
       "      <td>0.10230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>846381</td>\n",
       "      <td>M</td>\n",
       "      <td>15.85</td>\n",
       "      <td>23.95</td>\n",
       "      <td>103.70</td>\n",
       "      <td>782.7</td>\n",
       "      <td>0.08401</td>\n",
       "      <td>0.10020</td>\n",
       "      <td>0.09938</td>\n",
       "      <td>0.05364</td>\n",
       "      <td>...</td>\n",
       "      <td>16.84</td>\n",
       "      <td>27.66</td>\n",
       "      <td>112.00</td>\n",
       "      <td>876.5</td>\n",
       "      <td>0.1131</td>\n",
       "      <td>0.1924</td>\n",
       "      <td>0.2322</td>\n",
       "      <td>0.11190</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.06287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>84667401</td>\n",
       "      <td>M</td>\n",
       "      <td>13.73</td>\n",
       "      <td>22.61</td>\n",
       "      <td>93.60</td>\n",
       "      <td>578.3</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.22930</td>\n",
       "      <td>0.21280</td>\n",
       "      <td>0.08025</td>\n",
       "      <td>...</td>\n",
       "      <td>15.03</td>\n",
       "      <td>32.01</td>\n",
       "      <td>108.80</td>\n",
       "      <td>697.7</td>\n",
       "      <td>0.1651</td>\n",
       "      <td>0.7725</td>\n",
       "      <td>0.6943</td>\n",
       "      <td>0.22080</td>\n",
       "      <td>0.3596</td>\n",
       "      <td>0.14310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>84799002</td>\n",
       "      <td>M</td>\n",
       "      <td>14.54</td>\n",
       "      <td>27.54</td>\n",
       "      <td>96.73</td>\n",
       "      <td>658.8</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.15950</td>\n",
       "      <td>0.16390</td>\n",
       "      <td>0.07364</td>\n",
       "      <td>...</td>\n",
       "      <td>17.46</td>\n",
       "      <td>37.13</td>\n",
       "      <td>124.10</td>\n",
       "      <td>943.2</td>\n",
       "      <td>0.1678</td>\n",
       "      <td>0.6577</td>\n",
       "      <td>0.7026</td>\n",
       "      <td>0.17120</td>\n",
       "      <td>0.4218</td>\n",
       "      <td>0.13410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>848406</td>\n",
       "      <td>M</td>\n",
       "      <td>14.68</td>\n",
       "      <td>20.13</td>\n",
       "      <td>94.74</td>\n",
       "      <td>684.5</td>\n",
       "      <td>0.09867</td>\n",
       "      <td>0.07200</td>\n",
       "      <td>0.07395</td>\n",
       "      <td>0.05259</td>\n",
       "      <td>...</td>\n",
       "      <td>19.07</td>\n",
       "      <td>30.88</td>\n",
       "      <td>123.40</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>0.1464</td>\n",
       "      <td>0.1871</td>\n",
       "      <td>0.2914</td>\n",
       "      <td>0.16090</td>\n",
       "      <td>0.3029</td>\n",
       "      <td>0.08216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>84862001</td>\n",
       "      <td>M</td>\n",
       "      <td>16.13</td>\n",
       "      <td>20.68</td>\n",
       "      <td>108.10</td>\n",
       "      <td>798.8</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.20220</td>\n",
       "      <td>0.17220</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>...</td>\n",
       "      <td>20.96</td>\n",
       "      <td>31.48</td>\n",
       "      <td>136.80</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.4233</td>\n",
       "      <td>0.4784</td>\n",
       "      <td>0.20730</td>\n",
       "      <td>0.3706</td>\n",
       "      <td>0.11420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>849014</td>\n",
       "      <td>M</td>\n",
       "      <td>19.81</td>\n",
       "      <td>22.15</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>0.09831</td>\n",
       "      <td>0.10270</td>\n",
       "      <td>0.14790</td>\n",
       "      <td>0.09498</td>\n",
       "      <td>...</td>\n",
       "      <td>27.32</td>\n",
       "      <td>30.88</td>\n",
       "      <td>186.80</td>\n",
       "      <td>2398.0</td>\n",
       "      <td>0.1512</td>\n",
       "      <td>0.3150</td>\n",
       "      <td>0.5372</td>\n",
       "      <td>0.23880</td>\n",
       "      <td>0.2768</td>\n",
       "      <td>0.07615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8510426</td>\n",
       "      <td>B</td>\n",
       "      <td>13.54</td>\n",
       "      <td>14.36</td>\n",
       "      <td>87.46</td>\n",
       "      <td>566.3</td>\n",
       "      <td>0.09779</td>\n",
       "      <td>0.08129</td>\n",
       "      <td>0.06664</td>\n",
       "      <td>0.04781</td>\n",
       "      <td>...</td>\n",
       "      <td>15.11</td>\n",
       "      <td>19.26</td>\n",
       "      <td>99.70</td>\n",
       "      <td>711.2</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>0.1773</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.12880</td>\n",
       "      <td>0.2977</td>\n",
       "      <td>0.07259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8510653</td>\n",
       "      <td>B</td>\n",
       "      <td>13.08</td>\n",
       "      <td>15.71</td>\n",
       "      <td>85.63</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.12700</td>\n",
       "      <td>0.04568</td>\n",
       "      <td>0.03110</td>\n",
       "      <td>...</td>\n",
       "      <td>14.50</td>\n",
       "      <td>20.49</td>\n",
       "      <td>96.09</td>\n",
       "      <td>630.5</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.2776</td>\n",
       "      <td>0.1890</td>\n",
       "      <td>0.07283</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.08183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0     842517         M        20.57         17.77          132.90     1326.0   \n",
       "1   84300903         M        19.69         21.25          130.00     1203.0   \n",
       "2   84348301         M        11.42         20.38           77.58      386.1   \n",
       "3   84358402         M        20.29         14.34          135.10     1297.0   \n",
       "4     843786         M        12.45         15.70           82.57      477.1   \n",
       "5     844359         M        18.25         19.98          119.60     1040.0   \n",
       "6   84458202         M        13.71         20.83           90.20      577.9   \n",
       "7     844981         M        13.00         21.82           87.50      519.8   \n",
       "8   84501001         M        12.46         24.04           83.97      475.9   \n",
       "9     845636         M        16.02         23.24          102.70      797.8   \n",
       "10  84610002         M        15.78         17.89          103.60      781.0   \n",
       "11    846226         M        19.17         24.80          132.40     1123.0   \n",
       "12    846381         M        15.85         23.95          103.70      782.7   \n",
       "13  84667401         M        13.73         22.61           93.60      578.3   \n",
       "14  84799002         M        14.54         27.54           96.73      658.8   \n",
       "15    848406         M        14.68         20.13           94.74      684.5   \n",
       "16  84862001         M        16.13         20.68          108.10      798.8   \n",
       "17    849014         M        19.81         22.15          130.00     1260.0   \n",
       "18   8510426         B        13.54         14.36           87.46      566.3   \n",
       "19   8510653         B        13.08         15.71           85.63      520.0   \n",
       "\n",
       "    smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0           0.08474           0.07864         0.08690              0.07017   \n",
       "1           0.10960           0.15990         0.19740              0.12790   \n",
       "2           0.14250           0.28390         0.24140              0.10520   \n",
       "3           0.10030           0.13280         0.19800              0.10430   \n",
       "4           0.12780           0.17000         0.15780              0.08089   \n",
       "5           0.09463           0.10900         0.11270              0.07400   \n",
       "6           0.11890           0.16450         0.09366              0.05985   \n",
       "7           0.12730           0.19320         0.18590              0.09353   \n",
       "8           0.11860           0.23960         0.22730              0.08543   \n",
       "9           0.08206           0.06669         0.03299              0.03323   \n",
       "10          0.09710           0.12920         0.09954              0.06606   \n",
       "11          0.09740           0.24580         0.20650              0.11180   \n",
       "12          0.08401           0.10020         0.09938              0.05364   \n",
       "13          0.11310           0.22930         0.21280              0.08025   \n",
       "14          0.11390           0.15950         0.16390              0.07364   \n",
       "15          0.09867           0.07200         0.07395              0.05259   \n",
       "16          0.11700           0.20220         0.17220              0.10280   \n",
       "17          0.09831           0.10270         0.14790              0.09498   \n",
       "18          0.09779           0.08129         0.06664              0.04781   \n",
       "19          0.10750           0.12700         0.04568              0.03110   \n",
       "\n",
       "    ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0   ...         24.99          23.41           158.80      1956.0   \n",
       "1   ...         23.57          25.53           152.50      1709.0   \n",
       "2   ...         14.91          26.50            98.87       567.7   \n",
       "3   ...         22.54          16.67           152.20      1575.0   \n",
       "4   ...         15.47          23.75           103.40       741.6   \n",
       "5   ...         22.88          27.66           153.20      1606.0   \n",
       "6   ...         17.06          28.14           110.60       897.0   \n",
       "7   ...         15.49          30.73           106.20       739.3   \n",
       "8   ...         15.09          40.68            97.65       711.4   \n",
       "9   ...         19.19          33.88           123.80      1150.0   \n",
       "10  ...         20.42          27.28           136.50      1299.0   \n",
       "11  ...         20.96          29.94           151.70      1332.0   \n",
       "12  ...         16.84          27.66           112.00       876.5   \n",
       "13  ...         15.03          32.01           108.80       697.7   \n",
       "14  ...         17.46          37.13           124.10       943.2   \n",
       "15  ...         19.07          30.88           123.40      1138.0   \n",
       "16  ...         20.96          31.48           136.80      1315.0   \n",
       "17  ...         27.32          30.88           186.80      2398.0   \n",
       "18  ...         15.11          19.26            99.70       711.2   \n",
       "19  ...         14.50          20.49            96.09       630.5   \n",
       "\n",
       "    smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0             0.1238             0.1866           0.2416   \n",
       "1             0.1444             0.4245           0.4504   \n",
       "2             0.2098             0.8663           0.6869   \n",
       "3             0.1374             0.2050           0.4000   \n",
       "4             0.1791             0.5249           0.5355   \n",
       "5             0.1442             0.2576           0.3784   \n",
       "6             0.1654             0.3682           0.2678   \n",
       "7             0.1703             0.5401           0.5390   \n",
       "8             0.1853             1.0580           1.1050   \n",
       "9             0.1181             0.1551           0.1459   \n",
       "10            0.1396             0.5609           0.3965   \n",
       "11            0.1037             0.3903           0.3639   \n",
       "12            0.1131             0.1924           0.2322   \n",
       "13            0.1651             0.7725           0.6943   \n",
       "14            0.1678             0.6577           0.7026   \n",
       "15            0.1464             0.1871           0.2914   \n",
       "16            0.1789             0.4233           0.4784   \n",
       "17            0.1512             0.3150           0.5372   \n",
       "18            0.1440             0.1773           0.2390   \n",
       "19            0.1312             0.2776           0.1890   \n",
       "\n",
       "    concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.18600          0.2750                  0.08902  \n",
       "1                0.24300          0.3613                  0.08758  \n",
       "2                0.25750          0.6638                  0.17300  \n",
       "3                0.16250          0.2364                  0.07678  \n",
       "4                0.17410          0.3985                  0.12440  \n",
       "5                0.19320          0.3063                  0.08368  \n",
       "6                0.15560          0.3196                  0.11510  \n",
       "7                0.20600          0.4378                  0.10720  \n",
       "8                0.22100          0.4366                  0.20750  \n",
       "9                0.09975          0.2948                  0.08452  \n",
       "10               0.18100          0.3792                  0.10480  \n",
       "11               0.17670          0.3176                  0.10230  \n",
       "12               0.11190          0.2809                  0.06287  \n",
       "13               0.22080          0.3596                  0.14310  \n",
       "14               0.17120          0.4218                  0.13410  \n",
       "15               0.16090          0.3029                  0.08216  \n",
       "16               0.20730          0.3706                  0.11420  \n",
       "17               0.23880          0.2768                  0.07615  \n",
       "18               0.12880          0.2977                  0.07259  \n",
       "19               0.07283          0.3184                  0.08183  \n",
       "\n",
       "[20 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20) #Посмотрим на наши данные еще раз, видно, что заголовки появились."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568 entries, 0 to 567\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       568 non-null    int64  \n",
      " 1   diagnosis                568 non-null    object \n",
      " 2   radius_mean              568 non-null    float64\n",
      " 3   texture_mean             568 non-null    float64\n",
      " 4   perimeter_mean           568 non-null    float64\n",
      " 5   area_mean                568 non-null    float64\n",
      " 6   smoothness_mean          568 non-null    float64\n",
      " 7   compactness_mean         568 non-null    float64\n",
      " 8   concavity_mean           568 non-null    float64\n",
      " 9   concave points_mean      568 non-null    float64\n",
      " 10  symmetry_mean            568 non-null    float64\n",
      " 11  fractal_dimension_mean   568 non-null    float64\n",
      " 12  radius_se                568 non-null    float64\n",
      " 13  texture_se               568 non-null    float64\n",
      " 14  perimeter_se             568 non-null    float64\n",
      " 15  area_se                  568 non-null    float64\n",
      " 16  smoothness_se            568 non-null    float64\n",
      " 17  compactness_se           568 non-null    float64\n",
      " 18  concavity_se             568 non-null    float64\n",
      " 19  concave points_se        568 non-null    float64\n",
      " 20  symmetry_se              568 non-null    float64\n",
      " 21  fractal_dimension_se     568 non-null    float64\n",
      " 22  radius_worst             568 non-null    float64\n",
      " 23  texture_worst            568 non-null    float64\n",
      " 24  perimeter_worst          568 non-null    float64\n",
      " 25  area_worst               568 non-null    float64\n",
      " 26  smoothness_worst         568 non-null    float64\n",
      " 27  compactness_worst        568 non-null    float64\n",
      " 28  concavity_worst          568 non-null    float64\n",
      " 29  concave points_worst     568 non-null    float64\n",
      " 30  symmetry_worst           568 non-null    float64\n",
      " 31  fractal_dimension_worst  568 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info() #посмотрим на сводную информацию еще раз"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что целевая переменная 'diagnosis' должна быть перекодирована в числовой формат. Ниже приведена функция, которая сделает все это, включая все наши предыдущие действия. Также в ней будет выполнена нормализация данных при помощи функции StandardScaler()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path): #задаем функцию\n",
    "     ds = pd.read_csv(data_path, names=[\"id\", \"diagnosis\", \"radius_mean\", \"texture_mean\", \"perimeter_mean\", \"area_mean\",\n",
    "                                      \"smoothness_mean\", \"compactness_mean\", \"concavity_mean\", \"concave points_mean\",\n",
    "                                      \"symmetry_mean\", \"fractal_dimension_mean\", \"radius_se\", \"texture_se\",\n",
    "                                      \"perimeter_se\", \"area_se\", \"smoothness_se\", \"compactness_se\", \"concavity_se\",\n",
    "                                      \"concave points_se\", \"symmetry_se\", \"fractal_dimension_se\", \"radius_worst\",\n",
    "                                      \"texture_worst\", \"perimeter_worst\", \"area_worst\", \"smoothness_worst\",\n",
    "                                      \"compactness_worst\", \"concavity_worst\", \"concave points_worst\", \"symmetry_worst\",\n",
    "                                      \"fractal_dimension_worst\"]) #прописываем названия столбцов\n",
    "     y = ds['diagnosis'] #выделяем целевую переменную из общего объема данных\n",
    "     X = ds.drop('diagnosis', axis=1) #удаляем целевую переменную из обучающего множества\n",
    "     X = X.drop('id', axis=1) #удаляем не информативный столбец 'id'\n",
    "     i = len(X.columns)\n",
    "     X = X.drop(X.columns[i - 1], axis=1) #удаляем не информативный столбец 'fractal_dimension_worst'\n",
    "     y.replace(('M', 'B'), (1, 0), inplace=True) #делаем замену значений в целевой переменной на 0 и 1\n",
    "     sc = StandardScaler() #выполняем нормализацию данных, после чего наши данные преобразуются \n",
    "                           #из структуры датафрейм в обычный массив\n",
    "     sc.fit(X)\n",
    "     X_ans = sc.transform(X)\n",
    "     return X_ans, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data(\"Модуль 2_Тема 4. Онкология.csv\") #Применяем написанную функцию для обработки данных из файла\n",
    "# У нас сразу получаются два множества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.09706398, -2.07333501,  1.26993369, ...,  2.10952635,\n",
       "         2.29607613,  2.75062224],\n",
       "       [ 1.82982061, -0.35363241,  1.68595471, ..., -0.14674897,\n",
       "         1.0870843 , -0.24388967],\n",
       "       [ 1.57988811,  0.45618695,  1.56650313, ...,  0.85497394,\n",
       "         1.95500035,  1.152255  ],\n",
       "       ...,\n",
       "       [ 0.70228425,  2.0455738 ,  0.67267578, ...,  0.3267666 ,\n",
       "         0.41406869, -1.10454895],\n",
       "       [ 1.83834103,  2.33645719,  1.98252415, ...,  3.19760468,\n",
       "         2.28998549,  1.91908301],\n",
       "       [-1.80840125,  1.22179204, -1.81438851, ..., -1.30583065,\n",
       "        -1.74506282, -0.04813821]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X #Посмотрим как выглядит теперь множество Х, данные после нормализации не похожи на исходные значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# импортируем функцию, которая поможет нам разбить наши данные на обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Получили четыре множества: два для обучения, другие два - для тестирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm #импортируем нашу модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = svm.SVC(kernel='linear', C=1, gamma=1) #зададим начальные параметры для моделиz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, gamma=1, kernel='linear')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train , y_train) #выполним обучение модели при начальных параметрах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь видно, какие параметры задали мы, а какие параметры, также входящие в модель, были заполнены значениями по умолчанию.\n",
    "Попробуйте задать все значения по умолчанию (то есть не прописывать никаких значений в строке:\n",
    "best_model = svm.SVC(kernel='linear', C=1, gamma=1)) и посмотрите что получится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV # В этот раз тоже используем полный перебор параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = best_model.get_params() #зададим параметры по которым и будем осуществлять поиск\n",
    "tuned_params = {}\n",
    "for k, v in model_params.items():\n",
    "    tuned_params[k] = [v]\n",
    "tuned_params['gamma'] = range(1, 100)\n",
    "clf = GridSearchCV(best_model, tuned_params, cv=10, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "best_params = clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics              # импортируем метрики\n",
    "best_model = svm.SVC(**best_params)      # задаем найденные наилучшие параметры\n",
    "best_model.fit(X_train, y_train)         # обучаем модель\n",
    "predicted = best_model.predict(X_test)   # делаем предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used params: {'C': 1, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 1, 'kernel': 'linear', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "Evaluation:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97        71\n",
      "           1       0.93      0.98      0.95        43\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.97      0.96       114\n",
      "weighted avg       0.97      0.96      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Used params:', best_params)       # выведем наилучшие параметры\n",
    "print('Evaluation:\\n', metrics.classification_report(y_test, predicted))\n",
    "#лучшие значения метрик (те значения, которые поулчаются при наилучших параметрах модели)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим точность повысилась по сравнению с предыдущим методом. При этом мы с вами перебирали значения параметра \"gamma\", изменяя его от 1 до 100 и подбирая такое значение, при котором ошибка была бы минимальной.\n",
    "Поскольку мы не знаем изначально какие именно параметры нужно подбирать чтобы получить наилучший результат, то можно проводить подобный поиск несколько раз.\n",
    "Модифицируем код и выполним поиск по другим параметрам. При этом все наши команды мы разместим в одной исполняемой строчке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params:\n",
      " {'C': 6, 'kernel': 'rbf'}\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        71\n",
      "           1       0.95      0.95      0.95        43\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.96      0.96       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=svm.SVC()\n",
    "\n",
    "params = {'C': [6,7,8,9,10,11,12], \n",
    "          'kernel': ['linear','rbf']}\n",
    "\n",
    "model_svm = GridSearchCV(model, param_grid=params, n_jobs=-1)\n",
    "model_svm.fit(X_train,y_train)\n",
    "\n",
    "print(\"Best Params:\\n\",model_svm.best_params_)\n",
    "\n",
    "prediction=model_svm.predict(X_test)\n",
    "\n",
    "print(\"Report:\\n\",metrics.classification_report(prediction,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим мы получили аналогичные значения, изменяя другие параметры модели. Это говорит о стабильности получаемого решения.\n",
    "Также необходимо отметить тот факт, что не какой-то единой и только одной правильной формы подбора параметров. Если вы сравните эти два кусочка кода, то заметите, что они написаны немного по-разному, но при этом работают одинаково."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим сколько же ошибок сейчас делает наша модель. Для этого построим матрицу ошибок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(model_svm.fit(X_train, y_train), X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим из построенной матрицы ошибок построенная модель делает 4 ошибки (всего же строчек у нас 114), то есть правильно классифицированы 110 пациентов.\n",
    "Постройте матрицу ошибок для других моделей и сравните с ее помощью те результаты, которые мы получаем используя различные модели."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
